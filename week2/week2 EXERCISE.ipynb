{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aee62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variable and Create base models\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    print(\"OPENAI_API_KEY found...\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY not found...\")\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "openai = OpenAI(api_key=OPENAI_API_KEY)\n",
    "# openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2737c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an weather assistant helping users to get current temperature in a city\"\n",
    "system_message += \"Give short customer answers with location, temperature, humidity and windspeed\"\n",
    "system_message += \"always be accurate, if you are not sure, please say you don't know\"\n",
    "system_message += \"if you didn't get the correct data or face error in calling a method, explicitly call error in reading data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c506429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat method \n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create( \n",
    "        model = MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Chat UI using gradio\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593027c",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c113bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get live weather data given a city name.\n",
    "from geopy.geocoders import Nominatim\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "def get_coordinates(city_name: str):\n",
    "    geolocator = Nominatim(user_agent=\"weather_app\")\n",
    "    location = geolocator.geocode(city_name)\n",
    "    if location:\n",
    "        print(f\"City: {city_name} Latitude: {location.latitude}, Longitude: {location.longitude}\")\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        print(f\"Error in getting geo co-ordinates for {city_name}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "def get_metno_weather(lat: float, lon: float) -> Dict[str, str]:\n",
    "    url = f\"https://api.met.no/weatherapi/locationforecast/2.0/compact?lat={lat}&lon={lon}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"weather_app_example/1.0 github.com/yourusername\"\n",
    "    }\n",
    "    result: Dict[str, str] = {}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        timeseries = data['properties']['timeseries'][0]\n",
    "        details = timeseries['data']['instant']['details']\n",
    "        result[\"Temperature\"] = f\"{details['air_temperature']}Â°C\"\n",
    "        result[\"Humidity\"] = f\"{details['relative_humidity']}%\"\n",
    "        result[\"WindSpeed\"] = f\"{details['wind_speed']} m/s\"\n",
    "        print(f\"Temperature: {result[\"Temperature\"]} Humidity: {result[\"Humidity\"]} WindSpeed: {result[\"WindSpeed\"]}\")\n",
    "    else:\n",
    "        print(\"Error fetching weather data.\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> Dict[str, str]:\n",
    "    lat: float = 0.0\n",
    "    lon: float = 0.0\n",
    "    lat, lon = get_coordinates(city)\n",
    "    if lat is None or lon is None:\n",
    "        print(\"Error: Could not find coordinates for the city.\")\n",
    "        return {}\n",
    "    weather_result: Dict[str, str] = get_metno_weather(lat, lon)\n",
    "    return weather_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6dfc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get live weather\n",
    "city = \"chennai\"\n",
    "curr_weather = get_weather(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4156b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function to pass to openai\n",
    "\n",
    "weather_function = {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get the current weather information for a given city, including temperature, humidity, and wind speed.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the city to get weather information for.\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "# And this is included in a list of tools:\n",
    "tools = [{\"type\": \"function\", \"function\": weather_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle tool call\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    city = arguments.get(\"city\")\n",
    "    weather_data = get_weather(city=city)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"city\": city, \"weather\":weather_data}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    print(response)\n",
    "    return response, city\n",
    "\n",
    "\n",
    "# Chat method \n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create( \n",
    "        model = MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        f_response, city = handle_tool_call(message=message)\n",
    "        messages.append(message)\n",
    "        messages.append(f_response)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78356bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat, type='messages').launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa471be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61da171",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets add Multimodel\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# artist image generator for the given city and given weather condition.\n",
    "def artistic_image(city: str, weather: str):\n",
    "    prompt_msg = f\"An image representing the {city} city showing important tourist spots at this {weather} condition\"\n",
    "    image_response = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt_msg,\n",
    "        size=\"1024x1024\",\n",
    "        n=1,\n",
    "        response_format=\"b64_json\"\n",
    "    )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"mumbai\"\n",
    "curr_weather = get_weather(city)\n",
    "image = artistic_image(city, json.dumps(curr_weather))\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba93a1",
   "metadata": {},
   "source": [
    "## Add audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ae4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"onyx\",    # Also, try replacing onyx with alloy\n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b75d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"mumbai\"\n",
    "curr_weather = get_weather(city)\n",
    "\n",
    "temp = f\"Current temperature at {city} city is \\\n",
    "        {curr_weather[\"Temperature\"]} and \\\n",
    "        Humidity is {curr_weather[\"Humidity\"]} \\\n",
    "        and wind speed is {curr_weather[\"WindSpeed\"]}\"\n",
    "\n",
    "talker(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    image = None\n",
    "    \n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        image = artistic_image(city, json.dumps(response))\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        \n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "    # Comment out or delete the next line if you'd rather skip Audio for now..\n",
    "    talker(reply)\n",
    "    \n",
    "    return history, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51217ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import speech_recognition as sr\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Speech-to-text function using speech_recognition\n",
    "def transcribe_and_chat(audio, history):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as temp_audio:\n",
    "        temp_audio.write(audio)\n",
    "        temp_audio.flush()\n",
    "        with sr.AudioFile(temp_audio.name) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "            try:\n",
    "                text = recognizer.recognize_google(audio_data)\n",
    "                history += [{\"role\": \"user\", \"content\": text}]\n",
    "                os.unlink(temp_audio.name)  # Clean up temp file\n",
    "                return \"\", history\n",
    "            except sr.UnknownValueError:\n",
    "                return \"\", history + [{\"role\": \"assistant\", \"content\": \"Sorry, I couldn't understand that.\"}]\n",
    "            except sr.RequestError as e:\n",
    "                return \"\", history + [{\"role\": \"assistant\", \"content\": f\"Speech recognition error: {e}\"}]\n",
    "\n",
    "# UI\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "    with gr.Row():\n",
    "        mic = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"ð¤ Talk to the Assistant\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    # Text input function\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\": \"user\", \"content\": message}]\n",
    "        return \"\", history\n",
    "\n",
    "    # Connect Textbox\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "\n",
    "    # Connect Microphone\n",
    "    mic.change(transcribe_and_chat, inputs=[mic, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
